<html lang="en">

<head>
    <title> Searches and Sorts </title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
<iframe width="100%" height="32%" src="header.html"></iframe>
<h1> Searches </h1>
<p> Searches are very important for finding things in big data. </p>
<h2> Selection Search </h2>
<p> The selection search is the way any ordinary person would search data. Each element in the set is checked
    sequentially starting at the first element and ending at the last element. Selection search has a worst-case time
    complexity of O(n). Selection sort </p>
<h2> Binary Search </h2>
<p> Binary search is more efficient than selection search, having a worst-case time complexity of O(log n). The special
    thing about binary search is that the data must be sorted in order to work. The binary search starts in the middle
    of the set and checks if it is less than or greater than the target. Assuming the set is sorted in ascending order,
    if the target is greater than the element, the next check is done in the middle of the right half. If the target is
    lesser than the element, the next check is done in the middle of the left half of the set. </p>
<h1> Sorts </h1>
<p> Sorting is very important in all sorts of ways. Names are sorted on an attendance list, times are sorted in a race,
    blabhlabhab. That's why there are so many different sorting algorithms that all work so differently. </p>
<h2> Insertion and Selection Sort </h2>
<p> The simplest sorting algorithms may be the insertion and selection sort. They are not the most efficient sorts, but
    they are straight-forward. The largest similarity between the two sorts is that they partition the array into an
    unsorted and sorted area. At the beginning of the sort, the unsorted area has no elements and the sorted area takes
    up the entire array. As the sort progresses, the sorted area increases and the unsorted area decreases until the
    entire array is sorted. </p>
<p> The selection sort works by searching the unsorted part of the array for the minimum element and adding it to the
    sorted area. This is repeated until the array is sorted. </p>
<p> The insertion sort works by taking the first unsorted element and inserting it in the appropriate place in the
    sorted area. This is repeated until the array is sorted. </p>
<p> Selection sort always has a time complexity of O(n^2), whereas insertion only has a worst case of O(n^2) and has a
    best case of O(n) if the data is already sorted. </p>
<h2> Merge Sort </h2>
<p> The merge sort is a sort that is used widely for its low time complexity of (n log n), which stays the same no
    matter how the data is arranged. The merge sort is based off the doctrine "divide and conquer", which is breaking
    down the problem into smaller and more manageable pieces. The sort starts by splitting the array into halves, until
    each subarray is of length one. Then each sorted subarray is merged with another adjacent subarray. Since the
    subarrays are already sorted, less comparisons are required and the sort is optimized. </p>
<h2> Heap Sort </h2>
<p> The heap sort is a sort I learned as part of another assignment to present how a sorting algorithm works. It is
    similar to the merge sort (it has the same time complexity), but the way it works is very different. The heap sort
    uses the heap data structure, which is based off of the binary tree data structure. In a binary tree, every parent
    node has two children. A heap can either be a maximum or minimum heap. In a maximum heap, the parent is always
    greater than its children, and in a minimum heap the parent is less than its children. For the example shown below,
    a maximum heap will be used and is the most common heap used for the heap sort. </p>
<p></p>
</body>
